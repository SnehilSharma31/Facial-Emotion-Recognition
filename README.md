# <p align="center">ğŸ˜€Real-Time Smart Facial Emotion Detection using EmoAnalyzer Model with Minimum Computational CostğŸ™‚</p>

<div id="top"></div>

<h1> Research Paper Website: <a href="https://drive.google.com/file/d/1KtWeecVNCBYqm75CXy8RbheTCV4irtE8/view?usp=share_link">Visit NowğŸŒ</a></h1>

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h2>Table of ContentsğŸ§¾</h2>

- [Facial Emotion Detection using EmoAnalyzer Model Overview](#facial-emotion-detection-using-emoanalyzer-model-overview)
- [Abstractâœ¨](#abstract)
- [Technology UsedğŸš€](#technology-used)
- [Contact MeğŸ“](#contact-me)
<br>

Welcome to the Real-Time Smart Facial Emotion Detection project, powered by the EmoAnalyzer Model! This innovative initiative leverages cutting-edge technology to perform facial emotion analysis in real-time, with minimal computational cost, enabling seamless and efficient emotion detection.

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h2>Facial Emotion Detection using EmoAnalyzer Model OverviewğŸ“Œ</h2>
The primary goal of this project is to develop a real-time smart facial emotion detection system using the EmoAnalyzer Model, while minimizing computational costs. Through the integration of cutting-edge technology and data analysis, we aim to deliver accurate, instant facial emotion analysis. This system will empower users with efficient emotion detection capabilities, offering valuable insights without the burden of high computational expenses.
<p align="right">(<a href="#top">back to top</a>)</p>

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h2>Abstractâœ¨</h2>
Human emotions are not always communicated clearly through facial expressions, making facial recognition difficult due to variability. While traditional approaches like HOG and SIFT are used for pattern recognition in facial features, machine learning and neural networks have emerged as popular methods for emotion recognition. In this paper weâ€™ve employed four variations of CNN model and proposed a model named EmoAnalyzer to extract features and landmarks from facial images, classifying them into seven emotions using particularly grayscale images from FERC-2013 dataset. To be specific the Batch normalization along with dropout techniques are used here to prevent overfitting as well as improve accuracy, with model limitations selected based on training results. Test results shows VGG-16 model accurately identifies seven emotions at the accuracy of 67%, VGG-19 model at accuracy of 77%, CNN-V2 model at an accuracy of 64%, MobileNet-V2 model at an accuracy of 82.5% and the EmoAnalyzer (Proposed Model) at an accuracy of 97%.
<p align="right">(<a href="#top">back to top</a>)</p>

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h2>Technology UsedğŸš€</h2>

<p>
  <a href="https://www.w3schools.com/python/"> <img src="https://img.icons8.com/color/python" alt="Python" /></a>
  <a href="https://www.w3schools.com/ai_machine_learning/"> <img src="https://img.icons8.com/?size=64&id=yjSFO4TGzhsn&format=png" alt="ML" /></a>
  <a href="https://www.w3schools.com/python/numpy"> <img src="https://img.icons8.com/color/numpy" alt="Numpy" /></a>
  <a href="https://www.w3schools.com/python/pandas"> <img src="https://img.icons8.com/color/pandas" alt="Pandas" /></a>
  <a href="https://www.tutorialspoint.com/keras/index.htm"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Keras_logo.svg/240px-Keras_logo.svg.png" alt="Keras" width="64" height="64" /></a>
  <a href="https://www.w3schools.com/python/matplotlib_intro"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Matplotlib_icon.svg/180px-Matplotlib_icon.svg.png" alt="Matplotlib" width="64" height="64" /></a>
  <a href="https://www.w3schools.com/python/numpy/numpy_random_seaborn"> <img src="https://seaborn.pydata.org/_images/logo-mark-lightbg.svg" alt="seaborn" width="64" height="64" /></a>
  <a href="https://www.tutorialspoint.com/opencv/index.htm"> <img src="https://upload.wikimedia.org/wikipedia/commons/3/32/OpenCV_Logo_with_text_svg_version.svg" alt="OpenCV" width="64" height="64" /></a>
  
</p>
<p align="right">(<a href="#top">back to top</a>)</p>

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h2>Contact MeğŸ“</h2>

You can contact me through LinkedIn mentioned below.<br><br>
<a href="https://www.linkedin.com/in/snehilsharma31/"><img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" width="150px"></a>

<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h3>Give it a ğŸŒŸ if you â¤ the Research Project. Happy CodingğŸ‘¨â€ğŸ’»</h3>
<p align="right">(<a href="#top">back to top</a>)</p>
